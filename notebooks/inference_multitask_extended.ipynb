{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(\n",
    "    0, os.path.abspath(os.path.join(os.getcwd(), \"../../DermSynth3D_private\"))\n",
    ")\n",
    "from dermsynth3d.models.model import SkinDeepLabV3\n",
    "from dermsynth3d.datasets.datasets import (\n",
    "    Fitz17KAnnotations,\n",
    "    ImageDataset,\n",
    "    Ph2Dataset,\n",
    ")\n",
    "from dermsynth3d.utils.colorconstancy import shade_of_gray_cc\n",
    "from dermsynth3d.models.inference import inference_multitask\n",
    "from dermsynth3d.utils.evaluate import (\n",
    "    compute_results,\n",
    "    conf_mat_cells,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"dataset960\"\n",
    "model_name = \"may_18_2022_320x320_deeplab_paper\"\n",
    "model_name = \"synth_221-m-u_indoor\"\n",
    "dir_models = \"/mnt/d/models/image3d/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_path = '/mnt/d/models/image3d/dataset3500'\n",
    "# model_path = '/mnt/d/models/image3d/may_18_2022_320x320_deeplab_paper'\n",
    "# model_path = '/mnt/d/models/image3d/dataset960'\n",
    "# model_path = '/mnt/d/models/image3d/synth_221-m-u_indoor'\n",
    "model_path = os.path.join(dir_models, model_name)\n",
    "\n",
    "multitask_model = SkinDeepLabV3(multi_head=False, freeze_backbone=False)\n",
    "multitask_model.load_state_dict(torch.load(model_path), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "multitask_model = multitask_model.to(device)\n",
    "multitask_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (320, 320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes the model was pretrained using these values.\n",
    "preprocess_input = A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "img_preprocess = A.Compose(\n",
    "    [\n",
    "        preprocess_input,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# To force a resize of the input image.\n",
    "resize_func = A.Resize(\n",
    "    height=img_size[0], width=img_size[1], interpolation=cv2.INTER_CUBIC\n",
    ")\n",
    "# Perform spatial augmentation on both the image and mask.\n",
    "spatial_augment = A.Compose(\n",
    "    [\n",
    "        resize_func,\n",
    "    ]\n",
    ")\n",
    "resize_aspect_smallest = A.augmentations.geometric.resize.SmallestMaxSize(\n",
    "    max_size=img_size[0], always_apply=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_wounds = \"../../../wound-segmentation/data/Foot Ulcer Segmentation Challenge\"\n",
    "dir_wounds_train = os.path.join(dir_wounds, \"validation\")\n",
    "dir_wounds_train_images = os.path.join(dir_wounds_train, \"images\")\n",
    "dir_wounds_train_targets = os.path.join(dir_wounds_train, \"labels\")\n",
    "dir_pred_wounds = \"/mnt/d/predictions/wounds/deeplab_256_fivech4\"\n",
    "wound_ds = ImageDataset(\n",
    "    dir_wounds_train_images,\n",
    "    dir_wounds_train_targets,\n",
    "    dir_predictions=dir_pred_wounds,\n",
    "    image_extension=\".png\",\n",
    "    target_extension=\".png\",\n",
    "    spatial_transform=resize_aspect_smallest,\n",
    "    image_augment=None,\n",
    "    image_preprocess=img_preprocess,\n",
    "    totensor=ToTensorV2(transpose_mask=True),\n",
    "    color_constancy=shade_of_gray_cc,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wounds_dataloader = DataLoader(wound_ds, batch_size=1, shuffle=False)\n",
    "len(wounds_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index(pred, gt):\n",
    "    intersection = np.sum(pred & gt)\n",
    "    union = np.sum(pred | gt)\n",
    "\n",
    "    if gt.sum() == 0:\n",
    "        if pred.sum() == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdcad1a3e5004b0e980edb72a09183e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_skin_preds_wounds = \"/mnt/d/data/wounds/valid/preds\"\n",
    "fitz_test = inference_multitask(\n",
    "    max_imgs=len(wounds_dataloader),\n",
    "    model=multitask_model,\n",
    "    dataloader=wounds_dataloader,\n",
    "    device=device,\n",
    "    save_to_disk=True,\n",
    "    return_values=True,\n",
    "    dir_anatomy_preds=\"/mnt/d/data/wounds/valid/anatomy\",\n",
    "    dir_save_images=\"/mnt/d/data/wounds/valid/images\",\n",
    "    # dir_save_targets='/mnt/d/data/fitzpatrick17k/annotations/test/figs/targets',\n",
    "    dir_save_skin_preds=dir_skin_preds_wounds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27 \\pm 0.20\n"
     ]
    }
   ],
   "source": [
    "wounds_df = pd.DataFrame(\n",
    "    compute_results(wound_ds, dir_skin_preds_wounds, pred_ext=\".png\")\n",
    ")\n",
    "# Skin condition.\n",
    "print(\n",
    "    \"{:.2f} \\pm {:.2f}\".format(\n",
    "        wounds_df.lesion_ji.mean(),\n",
    "        wounds_df.lesion_ji.std(),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Fitzpatrick 17k test annotations</h2>\n",
    "\n",
    "https://github.com/mattgroh/fitzpatrick17k\n",
    "\n",
    "See instructions to download the images.\n",
    "\n",
    "Update `dir_fitz_images` to the directory containing the fitzpatrick17k images.\n",
    "\n",
    "Update `dir_fitz_test_annotations` to the subset of masks provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Where the fitzpatrick images are stored.\n",
    "dir_fitz_images = \"/mnt/d/data/fitzpatrick17k/data/finalfitz17k\"\n",
    "# Where the manual annotations are stored.\n",
    "dir_fitz_test_annotations = \"/mnt/d/data/fitzpatrick17k/annotations/annotations-20220516T041017Z-001/annotations\"\n",
    "# dir_fitz_test_predictions = '/mnt/d/data/fitzpatrick17k/annotations/annotations-20220516T041017Z-001/figs/skin'\n",
    "fitz_test_ds = Fitz17KAnnotations(\n",
    "    dir_images=dir_fitz_images,\n",
    "    dir_targets=dir_fitz_test_annotations,\n",
    "    image_extension=\".jpg\",\n",
    "    target_extension=\".png\",\n",
    "    spatial_transform=resize_aspect_smallest,\n",
    "    image_augment=None,\n",
    "    image_preprocess=img_preprocess,\n",
    "    totensor=ToTensorV2(transpose_mask=True),\n",
    "    color_constancy=shade_of_gray_cc,\n",
    ")\n",
    "fitz_test_dataloader = DataLoader(fitz_test_ds, batch_size=1, shuffle=False)\n",
    "len(fitz_test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_directories(dir_root: str, model_name: str):\n",
    "    paths = {}\n",
    "    paths[\"prob_segs\"] = os.path.join(dir_root, model_name, \"prob_segs\")\n",
    "    paths[\"pred_segs\"] = os.path.join(dir_root, model_name, \"pred_segs\")\n",
    "    paths[\"pred_anatomy\"] = os.path.join(dir_root, model_name, \"pred_anatomy\")\n",
    "    paths[\"images\"] = os.path.join(dir_root, model_name, \"images\")\n",
    "    paths[\"targets\"] = os.path.join(dir_root, model_name, \"targets\")\n",
    "\n",
    "    for key in paths:\n",
    "        if not os.path.isdir(paths[key]):\n",
    "            os.makedirs(paths[key])\n",
    "\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_fitz_evaluate = \"/mnt/d/data/fitzpatrick17k/evaluate\"\n",
    "fitz_paths = evaluate_directories(dir_root=dir_fitz_evaluate, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prob_segs': '/mnt/d/data/fitzpatrick17k/evaluate/synth_221-m-u_indoor/prob_segs',\n",
       " 'pred_segs': '/mnt/d/data/fitzpatrick17k/evaluate/synth_221-m-u_indoor/pred_segs',\n",
       " 'pred_anatomy': '/mnt/d/data/fitzpatrick17k/evaluate/synth_221-m-u_indoor/pred_anatomy',\n",
       " 'images': '/mnt/d/data/fitzpatrick17k/evaluate/synth_221-m-u_indoor/images',\n",
       " 'targets': '/mnt/d/data/fitzpatrick17k/evaluate/synth_221-m-u_indoor/targets'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitz_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034e01a7d9484357b2a00a0cc8af97c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fitz_test = inference_multitask(\n",
    "    max_imgs=len(fitz_test_dataloader),\n",
    "    model=multitask_model,\n",
    "    dataloader=fitz_test_dataloader,\n",
    "    device=device,\n",
    "    save_to_disk=True,\n",
    "    return_values=True,\n",
    "    dir_anatomy_preds=fitz_paths[\"pred_anatomy\"],\n",
    "    dir_save_images=fitz_paths[\"images\"],\n",
    "    dir_save_targets=fitz_paths[\"targets\"],\n",
    "    dir_save_skin_preds=fitz_paths[\"pred_segs\"],\n",
    "    dir_save_skin_probs=fitz_paths[\"prob_segs\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.51 \\pm 0.26\n",
      "0.79 \\pm 0.17\n",
      "0.52 \\pm 0.42\n"
     ]
    }
   ],
   "source": [
    "fitz_test_df = pd.DataFrame(\n",
    "    compute_results(fitz_test_ds, fitz_paths[\"pred_segs\"], pred_ext=\".png\")\n",
    ")\n",
    "# Skin condition.\n",
    "print(\n",
    "    \"{:.2f} \\pm {:.2f}\".format(\n",
    "        fitz_test_df.lesion_ji.mean(),\n",
    "        fitz_test_df.lesion_ji.std(),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Skin.\n",
    "print(\n",
    "    \"{:.2f} \\pm {:.2f}\".format(\n",
    "        fitz_test_df.skin_ji.mean(),\n",
    "        fitz_test_df.skin_ji.std(),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Nonskin.\n",
    "print(\n",
    "    \"{:.2f} \\pm {:.2f}\".format(\n",
    "        fitz_test_df.nonskin_ji.mean(),\n",
    "        fitz_test_df.nonskin_ji.std(),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_conf_mat(pred, gt):\n",
    "    tp = np.sum((pred == True) & (gt == True))\n",
    "    fp = np.sum((pred == True) & (gt == False))\n",
    "    tn = np.sum((pred == False) & (gt == False))\n",
    "    fn = np.sum((pred == False) & (gt == True))\n",
    "\n",
    "    return tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.sharedctypes import Value\n",
    "from dermsynth3d.utils.image import load_image\n",
    "from dermsynth3d.utils.evaluate import argmax_predictions\n",
    "\n",
    "ds = fitz_test_ds\n",
    "dir_pred_probs = fitz_paths[\"prob_segs\"]\n",
    "lesion_res = {\"tp\": 0, \"fp\": 0, \"tn\": 0, \"fn\": 0}\n",
    "skin_res = lesion_res.copy()\n",
    "back_res = lesion_res.copy()\n",
    "\n",
    "\n",
    "for image_id in ds.file_ids:\n",
    "    gt = np.asarray(ds.target(image_id)).astype(bool)\n",
    "    prob_filename = os.path.join(dir_pred_probs, image_id + \".png\")\n",
    "    pred = np.asarray(load_image(prob_filename))\n",
    "    # pred_seg = np.asarray(ds.prediction(image_id))\n",
    "    pred = argmax_predictions(pred)\n",
    "\n",
    "    for idx in range(3):\n",
    "        tp, fp, tn, fn = binary_conf_mat(pred[:, :, idx], gt[:, :, idx])\n",
    "        if idx == 0:\n",
    "            res = lesion_res\n",
    "        elif idx == 1:\n",
    "            res = skin_res\n",
    "        elif idx == 2:\n",
    "            res = back_res\n",
    "        else:\n",
    "            raise ValueError(\"Error: outside of expected range\")\n",
    "\n",
    "        res[\"tp\"] += tp\n",
    "        res[\"fp\"] += fp\n",
    "        res[\"tn\"] += tn\n",
    "        res[\"fn\"] += fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48 \n",
      "0.83 \n",
      "0.87 \n"
     ]
    }
   ],
   "source": [
    "# Single mesh model.\n",
    "for res in [lesion_res, skin_res, back_res]:\n",
    "    print(\"{:.2f} \".format(res[\"tp\"] / (res[\"tp\"] + res[\"fp\"] + res[\"fn\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57 \n",
      "0.88 \n",
      "0.86 \n"
     ]
    }
   ],
   "source": [
    "# 960 model.\n",
    "for res in [lesion_res, skin_res, back_res]:\n",
    "    print(\"{:.2f} \".format(res[\"tp\"] / (res[\"tp\"] + res[\"fp\"] + res[\"fn\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55 \n",
      "0.89 \n",
      "0.89 \n"
     ]
    }
   ],
   "source": [
    "# Full paper model\n",
    "for res in [lesion_res, skin_res, back_res]:\n",
    "    print(\"{:.2f} \".format(res[\"tp\"] / (res[\"tp\"] + res[\"fp\"] + res[\"fn\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7803022936721442"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp / (tp + fp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7803022936721442"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pred[:, :, idx] & gt[:, :, idx]) / np.sum(pred[:, :, idx] | gt[:, :, idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('bool')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_seg.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8f644249d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pred_seg * 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>PH2 results</h2>\n",
    "\n",
    "https://www.fc.up.pt/addi/ph2%20database.html\n",
    "\n",
    "Update `dir_images` to your path to the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "resize_aspect_longest = A.augmentations.geometric.resize.LongestMaxSize(\n",
    "    max_size=img_size[0], always_apply=True\n",
    ")\n",
    "\n",
    "ph2_img_augment = A.Compose(\n",
    "    [\n",
    "        A.GaussianBlur(blur_limit=(9, 9), always_apply=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ph2_ds = Ph2Dataset(\n",
    "    dir_images=\"/mnt/d/data/PH2Dataset/PH2Dataset/PH2 Dataset images\",\n",
    "    dir_targets=\"/mnt/d/data/PH2Dataset/PH2Dataset/PH2 Dataset images\",\n",
    "    name=\"ph2\",\n",
    "    image_extension=\".bmp\",\n",
    "    target_extension=\".bmp\",\n",
    "    image_augment=ph2_img_augment,\n",
    "    spatial_transform=resize_aspect_longest,\n",
    "    image_preprocess=img_preprocess,\n",
    "    totensor=ToTensorV2(transpose_mask=True),\n",
    "    color_constancy=shade_of_gray_cc,\n",
    ")\n",
    "print(len(ph2_ds))\n",
    "ph2_dataloader = DataLoader(ph2_ds, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22c61ae61ac42288154a6d17379d6e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_skin_preds_ph2_test = \"/mnt/d/predictions/ph2/figs/skin\"\n",
    "ph2_preds = inference_multitask(\n",
    "    max_imgs=len(ph2_dataloader),\n",
    "    model=multitask_model,\n",
    "    dataloader=ph2_dataloader,\n",
    "    device=device,\n",
    "    save_to_disk=True,\n",
    "    return_values=False,\n",
    "    dir_save_images=\"/mnt/d/predictions/ph2/figs/images\",\n",
    "    dir_save_targets=\"/mnt/d/predictions/ph2/figs/targets\",\n",
    "    dir_save_skin_preds=dir_skin_preds_ph2_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.56 \\pm 0.20\n"
     ]
    }
   ],
   "source": [
    "ph2_test_df = pd.DataFrame(\n",
    "    compute_results(ph2_ds, dir_skin_preds_ph2_test, pred_ext=\".bmp\")\n",
    ")\n",
    "# Skin condition.\n",
    "print(\n",
    "    \"{:.2f} \\pm {:.2f}\".format(\n",
    "        ph2_test_df.lesion_ji.mean(),\n",
    "        ph2_test_df.lesion_ji.std(),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Dermofit results</h2>\n",
    "\n",
    "https://licensing.edinburgh-innovations.ed.ac.uk/product/dermofit-image-library\n",
    "\n",
    "Requires a license and a fee.\n",
    "\n",
    "Update `dir_images` and `dir_targets` to your paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300\n"
     ]
    }
   ],
   "source": [
    "dermofit_img_augment = A.Compose(\n",
    "    [\n",
    "        A.GaussianBlur(blur_limit=(3, 3), always_apply=True),\n",
    "    ]\n",
    ")\n",
    "dermofit_ds = ImageDataset(\n",
    "    dir_images=\"/mnt/d/data/DermoFit_Segmentation/images\",\n",
    "    dir_targets=\"/mnt/d/data/DermoFit_Segmentation/targets\",\n",
    "    # dir_predictions='/mnt/d/data/DermoFit_Segmentation/predictions',\n",
    "    name=\"dermofit\",\n",
    "    image_extension=\".png\",\n",
    "    target_extension=\".png\",\n",
    "    image_augment=None,  # dermofit_img_augment,#dermofit_img_augment,\n",
    "    spatial_transform=resize_aspect_smallest,  # resize_aspect_longest, #resize_aspect_smallest, #spatial_augment,\n",
    "    image_preprocess=img_preprocess,\n",
    "    totensor=ToTensorV2(transpose_mask=True),\n",
    "    color_constancy=shade_of_gray_cc,\n",
    ")\n",
    "print(len(dermofit_ds))\n",
    "dermofit_dataloader = DataLoader(dermofit_ds, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40d4db3dd44479cb3dbdf7ba68e7393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_skin_preds_dermofit = \"/mnt/d/data/DermoFit_Segmentation/predictions\"\n",
    "dermofit_preds = inference_multitask(\n",
    "    max_imgs=len(dermofit_dataloader),\n",
    "    model=multitask_model,\n",
    "    dataloader=dermofit_dataloader,\n",
    "    device=device,\n",
    "    save_to_disk=True,\n",
    "    return_values=False,\n",
    "    dir_save_skin_preds=dir_skin_preds_dermofit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58 \\pm 0.22\n"
     ]
    }
   ],
   "source": [
    "dermofit_df = pd.DataFrame(\n",
    "    compute_results(dermofit_ds, dir_skin_preds_dermofit, pred_ext=\".png\")\n",
    ")\n",
    "# Skin condition.\n",
    "print(\n",
    "    \"{:.2f} \\pm {:.2f}\".format(\n",
    "        dermofit_df.lesion_ji.mean(),\n",
    "        dermofit_df.lesion_ji.std(),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Pratheepan results on FacePhoto</h2>\n",
    "\n",
    "Data from:\n",
    "https://web.fsktm.um.edu.my/~cschan/downloads_skin_dataset.html\n",
    "\n",
    "Update `dir_images` and `dir_targets` to your data paths to the images and skin masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pratheepan_ds = ImageDataset(\n",
    "    dir_images=\"/mnt/d/data/Face_Dataset/Pratheepan_Dataset/FacePhoto\",\n",
    "    dir_targets=\"/mnt/d/data/Face_Dataset/Ground_Truth/GroundT_FacePhoto\",\n",
    "    name=\"pratheepan\",\n",
    "    image_extension=\".jpg\",\n",
    "    target_extension=\".png\",\n",
    "    image_augment=None,\n",
    "    spatial_transform=resize_aspect_smallest,\n",
    "    image_preprocess=img_preprocess,\n",
    "    totensor=ToTensorV2(transpose_mask=True),\n",
    "    color_constancy=shade_of_gray_cc,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00cfc0b24217430a9d84240cfc11efd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_skin_preds_pratheepan = (\n",
    "    \"/mnt/d/data/Face_Dataset/Pratheepan_Dataset/predictions/FacePhoto/skin\"\n",
    ")\n",
    "pratheepan_dataloader = DataLoader(pratheepan_ds, batch_size=1, shuffle=False)\n",
    "pratheepan_preds = inference_multitask(\n",
    "    max_imgs=len(pratheepan_ds),\n",
    "    model=multitask_model,\n",
    "    dataloader=pratheepan_dataloader,\n",
    "    device=device,\n",
    "    save_to_disk=True,\n",
    "    return_values=False,\n",
    "    dir_anatomy_preds=\"/mnt/d/data/Face_Dataset/Pratheepan_Dataset/predictions/FacePhoto/anatomy\",\n",
    "    dir_save_skin_preds=dir_skin_preds_pratheepan,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77 \\pm 0.14\n"
     ]
    }
   ],
   "source": [
    "pratheepan_df = pd.DataFrame(\n",
    "    compute_results(pratheepan_ds, dir_skin_preds_pratheepan, pred_ext=\".png\")\n",
    ")\n",
    "# Skin condition.\n",
    "print(\n",
    "    \"{:.2f} \\pm {:.2f}\".format(\n",
    "        pratheepan_df.skin_ji.mean(),\n",
    "        pratheepan_df.skin_ji.std(),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = conf_mat_cells(pratheepan_ds, dir_skin_preds_pratheepan, \".png\")\n",
    "tps = res[\"tps\"]\n",
    "fps = res[\"fps\"]\n",
    "fns = res[\"fns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8578159369564877"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = (2 * np.sum(tps)) / ((2 * np.sum(tps)) + np.sum(fps) + np.sum(fns))\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "`   `"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6448a6cebda3065c9193e50ff51184523b72f29008470b17ce3f21a1918c09fd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch3dv2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
