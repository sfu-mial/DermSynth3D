{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(\n",
    "    0, os.path.abspath(os.path.join(os.getcwd(), \"../../DermSynth3D_private\"))\n",
    ")\n",
    "\n",
    "from dermsynth3d.datasets.datasets import (\n",
    "    ImageDataset,\n",
    "    SynthDataset_Detection,\n",
    "    RealDataset_Detection,\n",
    ")\n",
    "from dermsynth3d.models.model import faster_rcnn_texture_model\n",
    "from dermsynth3d.utils.evaluate_detection import (\n",
    "    evaluate_detection,\n",
    ")\n",
    "from dermsynth3d.utils.utils import (\n",
    "    MetricLogger,\n",
    "    SmoothedValue,\n",
    "    warmup_lr_scheduler,\n",
    "    reduce_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_model = faster_rcnn_texture_model(\n",
    "    device,\n",
    "    num_classes=2,\n",
    "    max_input_size=img_size[0],\n",
    "    pretrained_backbone=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_model = det_model.to(device)\n",
    "det_model.train()\n",
    "params = [p for p in det_model.parameters() if p.requires_grad]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes the model was pretrained using these values.\n",
    "preprocess_input = A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "img_preprocess = A.Compose(\n",
    "    [\n",
    "        preprocess_input,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# To force a resize of the input image.\n",
    "resize_func = A.Resize(height=img_size[0], width=img_size[1])\n",
    "\n",
    "# Perform spatial augmentation on both the image and mask.\n",
    "spatial_augment = A.Compose(\n",
    "    [\n",
    "        A.HorizontalFlip(),\n",
    "        A.RandomRotate90(),\n",
    "        resize_func,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Different types of augmentations on the image.\n",
    "min_v = 0.8\n",
    "max_v = 1.2\n",
    "img_augment = A.Compose(\n",
    "    [\n",
    "        A.ColorJitter(\n",
    "            brightness=(min_v, max_v),\n",
    "            contrast=(min_v, max_v),\n",
    "            saturation=(min_v, max_v),\n",
    "            hue=(-0.025, 0.025),\n",
    "        ),\n",
    "        A.ISONoise(color_shift=(0.01, 0.1), intensity=(0.1, 0.75), always_apply=False),\n",
    "        A.GaussianBlur(blur_limit=(3, 3)),\n",
    "        A.ImageCompression(10, 100),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Point to the synthetic data you created.\n",
    "dir_images = \"../data/all_data/images\"\n",
    "dir_targets = \"../data/all_data/targets\"\n",
    "\n",
    "synth_ds = SynthDataset_Detection(\n",
    "    dir_images=dir_images,\n",
    "    dir_targets=dir_targets,\n",
    "    name=\"synth_train\",\n",
    "    spatial_transform=spatial_augment,\n",
    "    image_augment=img_augment,\n",
    "    image_preprocess=preprocess_input,\n",
    "    target_preprocess=None,\n",
    "    target_extension=\".npz\",\n",
    "    totensor=ToTensorV2(transpose_mask=True),\n",
    ")\n",
    "\n",
    "print(len(synth_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "val_spatial_augment = A.Compose(\n",
    "    [\n",
    "        resize_func,\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "real_val_ds = RealDataset_Detection(\n",
    "    dir_images=\"../data/FUSeg/validation/images\",\n",
    "    dir_targets=\"../data/FUSeg/validation/labels\",\n",
    "    name=\"real_val\",\n",
    "    image_extension=\".png\",\n",
    "    target_extension=\".png\",\n",
    "    image_augment=None,\n",
    "    spatial_transform=val_spatial_augment,\n",
    "    image_preprocess=img_preprocess,\n",
    "    totensor=ToTensorV2(transpose_mask=True),\n",
    ")\n",
    "\n",
    "\n",
    "print(len(real_val_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq):\n",
    "    model.train()\n",
    "    metric_logger = MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter(\"lr\", SmoothedValue(window_size=1, fmt=\"{value:.6f}\"))\n",
    "    header = \"Epoch: [{}]\".format(epoch)\n",
    "\n",
    "    lr_scheduler = None\n",
    "    if epoch == 0:\n",
    "        warmup_factor = 1.0 / 1000\n",
    "        warmup_iters = min(1000, len(data_loader) - 1)\n",
    "\n",
    "        lr_scheduler = warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n",
    "\n",
    "    for _, _, images, masks, targets in metric_logger.log_every(\n",
    "        data_loader, print_freq, header\n",
    "    ):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        # reduce losses over all GPUs for logging purposes\n",
    "        loss_dict_reduced = reduce_dict(loss_dict)\n",
    "        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
    "\n",
    "        loss_value = losses_reduced.item()\n",
    "\n",
    "        if not math.isfinite(loss_value):\n",
    "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
    "            print(loss_dict_reduced)\n",
    "            sys.exit(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n",
    "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "    return metric_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader for training the Faster RCNN.\n",
    "batch_size = 8\n",
    "train_dataloader = DataLoader(\n",
    "    synth_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "batch_size = 8\n",
    "val_dataloader = DataLoader(\n",
    "    real_val_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "lr = 0.001\n",
    "momentum = 0.95\n",
    "weight_decay = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(\n",
    "    params,\n",
    "    lr=lr,\n",
    "    momentum=momentum,\n",
    "    weight_decay=weight_decay,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_stats = []\n",
    "max_valid_iou = 0\n",
    "training_epoch = 0\n",
    "\n",
    "dir_save_models = \"/path/to/save/model\"\n",
    "if not os.path.isdir(dir_save_models):\n",
    "    os.mkdir(dir_save_models)\n",
    "\n",
    "# Turn on the training mode for the model.\n",
    "for epoch in range(num_epochs):\n",
    "    det_model.train()\n",
    "    log = train_one_epoch(\n",
    "        det_model,\n",
    "        optimizer,\n",
    "        train_dataloader,\n",
    "        device,\n",
    "        epoch,\n",
    "        print_freq=20,\n",
    "    )\n",
    "    det_model.eval()\n",
    "    centroid_result, iou_result = evaluate_detection(det_model, val_dataloader, device)\n",
    "\n",
    "    ap = pd.DataFrame(centroid_result).ap.mean()\n",
    "    iou = pd.DataFrame(iou_result).iou.mean()\n",
    "    print(\"centroid_result, ap:\", ap)\n",
    "    print(\"iou_result, iou:\", iou)\n",
    "\n",
    "    if iou > max_valid_iou:\n",
    "        max_valid_iou = iou\n",
    "        # Save model to disk\n",
    "        print(\"Saving model to disk. iou={}\".format(iou))\n",
    "        torch.save(\n",
    "            det_model.state_dict(),\n",
    "            os.path.join(\n",
    "                dir_save_models, \"model_state_dict_patches\" + str(training_epoch)\n",
    "            ),\n",
    "        )\n",
    "        torch.save(\n",
    "            det_model,\n",
    "            os.path.join(dir_save_models, \"model_patches\" + str(training_epoch)),\n",
    "        )\n",
    "\n",
    "    training_stats.append(\n",
    "        {\n",
    "            \"epoch\": training_epoch,\n",
    "            \"valid_iou\": iou,\n",
    "            \"valid_ap\": ap,\n",
    "            \"train_loss\": log.meters[\"loss\"].value,\n",
    "        }\n",
    "    )\n",
    "    training_epoch = training_epoch + 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "377c28a50044843c88a43bc5a026e28784430be9ba823332f2819727b62f9bca"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('image3d')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
